{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339},{"sourceId":10122088,"sourceType":"datasetVersion","datasetId":6245920},{"sourceId":191313,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":163079,"modelId":185438}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **STEP 1: Install and Import Libraries**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nimport timm\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom torchvision.datasets import ImageFolder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T18:39:18.635192Z","iopub.execute_input":"2024-12-07T18:39:18.636019Z","iopub.status.idle":"2024-12-07T18:39:18.640197Z","shell.execute_reply.started":"2024-12-07T18:39:18.635984Z","shell.execute_reply":"2024-12-07T18:39:18.639335Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **STEP 2: Prepare the Dataset**","metadata":{}},{"cell_type":"code","source":"# Training transformations with augmentation\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(30),\n    transforms.RandomResizedCrop((224, 224)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Validation transformations (no augmentation)\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T20:36:38.150446Z","iopub.execute_input":"2024-12-06T20:36:38.151123Z","iopub.status.idle":"2024-12-06T20:36:38.157451Z","shell.execute_reply.started":"2024-12-06T20:36:38.151089Z","shell.execute_reply":"2024-12-06T20:36:38.156466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport pandas as pd\n\n# Define dataset paths\ndataset_path = '/kaggle/input/skin-cancer-mnist-ham10000/'\nimage_dirs = [\n    os.path.join(dataset_path, 'HAM10000_images_part_1'),\n    os.path.join(dataset_path, 'HAM10000_images_part_2')\n]\nmetadata_path = os.path.join(dataset_path, 'HAM10000_metadata.csv')\n\n# Load metadata\nmetadata = pd.read_csv(metadata_path)\nprint(metadata.head())  # Display metadata to understand structure","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T20:50:01.970000Z","iopub.execute_input":"2024-12-06T20:50:01.970763Z","iopub.status.idle":"2024-12-06T20:50:02.943447Z","shell.execute_reply.started":"2024-12-06T20:50:01.970714Z","shell.execute_reply":"2024-12-06T20:50:02.942470Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create output directory\norganized_dataset_path = '/kaggle/working/organized_dataset'\nos.makedirs(organized_dataset_path, exist_ok=True)\n\n# Create class-specific folders\nfor label in metadata['dx'].unique():\n    os.makedirs(os.path.join(organized_dataset_path, label), exist_ok=True)\n\n# Move images into corresponding class folders\nfor _, row in metadata.iterrows():\n    image_id = row['image_id']\n    label = row['dx']\n\n    # Find the image in either directory\n    src_path = None\n    for image_dir in image_dirs:\n        potential_path = os.path.join(image_dir, image_id + '.jpg')\n        if os.path.exists(potential_path):\n            src_path = potential_path\n            break\n\n    # Copy image to the organized directory\n    if src_path:\n        dst_path = os.path.join(organized_dataset_path, label, image_id + '.jpg')\n        shutil.copy(src_path, dst_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T20:50:24.586319Z","iopub.execute_input":"2024-12-06T20:50:24.587065Z","iopub.status.idle":"2024-12-06T20:52:14.885605Z","shell.execute_reply.started":"2024-12-06T20:50:24.587032Z","shell.execute_reply":"2024-12-06T20:52:14.884850Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **STEP 3: Load the Dataset**","metadata":{}},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom sklearn.model_selection import train_test_split\n\n# Load the entire dataset\nfull_dataset = ImageFolder(root=organized_dataset_path)\n\n# Stratified split into training and validation indices\ntrain_indices, val_indices = train_test_split(\n    list(range(len(full_dataset))),\n    stratify=[sample[1] for sample in full_dataset.samples],  # Use class labels for stratification\n    test_size=0.2,\n    random_state=42,\n)\n\n# Create subsets\ntrain_subset = torch.utils.data.Subset(full_dataset, train_indices)\nval_subset = torch.utils.data.Subset(full_dataset, val_indices)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T21:24:14.468140Z","iopub.execute_input":"2024-12-06T21:24:14.468507Z","iopub.status.idle":"2024-12-06T21:24:14.511741Z","shell.execute_reply.started":"2024-12-06T21:24:14.468467Z","shell.execute_reply":"2024-12-06T21:24:14.510885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms\n\n# Training transformations with augmentation\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(30),\n    transforms.RandomResizedCrop((224, 224)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Validation transformations (no augmentation)\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Apply transformations to subsets\ntrain_dataset = torch.utils.data.Subset(ImageFolder(organized_dataset_path, transform=train_transform), train_indices)\nval_dataset = torch.utils.data.Subset(ImageFolder(organized_dataset_path, transform=val_transform), val_indices)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T21:24:31.665537Z","iopub.execute_input":"2024-12-06T21:24:31.666381Z","iopub.status.idle":"2024-12-06T21:24:31.924405Z","shell.execute_reply.started":"2024-12-06T21:24:31.666344Z","shell.execute_reply":"2024-12-06T21:24:31.923455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Define DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n\n# Check the sizes\nprint(f\"Number of training samples: {len(train_dataset)}\")\nprint(f\"Number of validation samples: {len(val_dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T21:24:44.593630Z","iopub.execute_input":"2024-12-06T21:24:44.594358Z","iopub.status.idle":"2024-12-06T21:24:44.599891Z","shell.execute_reply.started":"2024-12-06T21:24:44.594323Z","shell.execute_reply":"2024-12-06T21:24:44.598957Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **STEP 4: Load the Model**","metadata":{}},{"cell_type":"code","source":"import timm\nfrom torch import nn\n\n# Load pre-trained EfficientNet model\nmodel = timm.create_model('efficientnet_b0', pretrained=True)\n\n# Modify the classification head\nmodel.classifier = nn.Linear(model.classifier.in_features, len(full_dataset.classes))\n\n# Move model to GPU\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T21:25:00.554208Z","iopub.execute_input":"2024-12-06T21:25:00.554915Z","iopub.status.idle":"2024-12-06T21:25:01.384565Z","shell.execute_reply.started":"2024-12-06T21:25:00.554879Z","shell.execute_reply":"2024-12-06T21:25:01.383704Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **STEP 5: Define Loss and Optimizer**","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Compute class weights\nclass_counts = [len([i for i in train_indices if full_dataset.samples[i][1] == c]) for c in range(len(full_dataset.classes))]\nclass_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\nclass_weights = class_weights / class_weights.sum()  # Normalize\nclass_weights = class_weights.to(device)\n\n# Define weighted loss\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\n\n# Define optimizer and scheduler\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T21:25:15.559675Z","iopub.execute_input":"2024-12-06T21:25:15.560039Z","iopub.status.idle":"2024-12-06T21:25:15.592655Z","shell.execute_reply.started":"2024-12-06T21:25:15.560012Z","shell.execute_reply":"2024-12-06T21:25:15.591795Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **STEP 6: Train the Model**","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20, patience=3):\n    best_val_loss = float('inf')\n    early_stop_counter = 0\n\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n        \n        # Training phase\n        model.train()\n        running_loss, correct, total = 0.0, 0, 0\n        \n        for images, labels in tqdm(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            # Backward pass and optimization\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n        train_loss = running_loss / len(train_loader)\n        train_accuracy = correct / total\n        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n        \n        # Validation phase\n        model.eval()\n        val_loss, correct, total = 0.0, 0, 0\n        \n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, preds = torch.max(outputs, 1)\n                correct += (preds == labels).sum().item()\n                total += labels.size(0)\n\n        val_loss = val_loss / len(val_loader)\n        val_accuracy = correct / total\n        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n        \n        # Early stopping\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            early_stop_counter = 0\n            torch.save(model.state_dict(), '/kaggle/working/efficientnet_best.pth')\n            print(\"Saved best model.\")\n        else:\n            early_stop_counter += 1\n            if early_stop_counter >= patience:\n                print(\"Early stopping triggered.\")\n                break\n\n        # Step scheduler\n        scheduler.step()\n\n# Train the model\ntrain_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T21:27:07.827468Z","iopub.execute_input":"2024-12-06T21:27:07.828341Z","iopub.status.idle":"2024-12-06T21:37:15.933716Z","shell.execute_reply.started":"2024-12-06T21:27:07.828299Z","shell.execute_reply":"2024-12-06T21:37:15.932655Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **STEP 7: Evaluate the Model**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\n# Load the best model\nmodel.load_state_dict(torch.load('/kaggle/working/efficientnet_best.pth'))\nmodel.eval()\n\n# Evaluate on validation data\nall_preds, all_labels = [], []\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Classification report and confusion matrix\nprint(classification_report(all_labels, all_preds, target_names=full_dataset.classes))\nprint(confusion_matrix(all_labels, all_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T21:39:27.862376Z","iopub.execute_input":"2024-12-06T21:39:27.863239Z","iopub.status.idle":"2024-12-06T21:39:37.181526Z","shell.execute_reply.started":"2024-12-06T21:39:27.863203Z","shell.execute_reply":"2024-12-06T21:39:37.180461Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms\nfrom PIL import Image\n\n# Define the test image transformation\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:44:48.606649Z","iopub.execute_input":"2024-12-07T08:44:48.607557Z","iopub.status.idle":"2024-12-07T08:44:48.612374Z","shell.execute_reply.started":"2024-12-07T08:44:48.607516Z","shell.execute_reply":"2024-12-07T08:44:48.611448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport timm\nfrom torch import nn\n\n# Initialize EfficientNet architecture\nmodel = timm.create_model('efficientnet_b0', pretrained=False)  # Ensure architecture matches\nmodel.classifier = nn.Linear(model.classifier.in_features, 7)   # Adjust output classes\n\n# Map model to the correct device\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# Load the state dict\nmodel.load_state_dict(torch.load('/kaggle/input/effnet-for-sc/pytorch/default/1/efficientnet_best.pth', map_location=device))\nmodel = model.to(device)\nmodel.eval()  # Set to evaluation mode\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:47:25.900912Z","iopub.execute_input":"2024-12-07T08:47:25.901256Z","iopub.status.idle":"2024-12-07T08:47:26.102456Z","shell.execute_reply.started":"2024-12-07T08:47:25.901226Z","shell.execute_reply":"2024-12-07T08:47:26.101579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_image(image_path, model, transform, device='cuda'):\n    # Load and preprocess the image\n    image = Image.open(image_path).convert('RGB')  # Ensure RGB format\n    input_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n\n    # Make prediction\n    with torch.no_grad():\n        outputs = model(input_tensor)\n        _, predicted_class = torch.max(outputs, 1)\n\n    # Map the predicted class index to the class label\n    class_idx = predicted_class.item()\n    class_label = full_dataset.classes[class_idx]  # `full_dataset` from earlier code\n\n    return class_label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:47:35.852883Z","iopub.execute_input":"2024-12-07T08:47:35.853590Z","iopub.status.idle":"2024-12-07T08:47:35.858716Z","shell.execute_reply.started":"2024-12-07T08:47:35.853552Z","shell.execute_reply":"2024-12-07T08:47:35.857756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\n# Evaluate on the validation data\nall_preds, all_labels = [], []\nmodel.eval()  # Set model to evaluation mode\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n\n        # Collect predictions and true labels\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Generate a classification report\nclass_names = full_dataset.classes\nprint(\"Classification Report:\")\nprint(classification_report(all_labels, all_preds, target_names=class_names))\n\n# Confusion matrix\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(all_labels, all_preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T22:06:24.828795Z","iopub.execute_input":"2024-12-06T22:06:24.829648Z","iopub.status.idle":"2024-12-06T22:06:34.215322Z","shell.execute_reply.started":"2024-12-06T22:06:24.829608Z","shell.execute_reply":"2024-12-06T22:06:34.214226Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import label_binarize\nimport numpy as np\n\n# Binarize the labels for multi-class ROC/AUC\nnum_classes = len(class_names)\nall_labels_bin = label_binarize(all_labels, classes=list(range(num_classes)))\nall_preds_bin = label_binarize(all_preds, classes=list(range(num_classes)))\n\n# Compute ROC curve and AUC for each class\nfpr, tpr, roc_auc = {}, {}, {}\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(all_labels_bin[:, i], all_preds_bin[:, i])\n    roc_auc[i] = roc_auc_score(all_labels_bin[:, i], all_preds_bin[:, i])\n\n# Plot ROC curves\nplt.figure(figsize=(10, 8))\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], label=f\"{class_names[i]} (AUC = {roc_auc[i]:.2f})\")\n\nplt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")  # Diagonal line\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve for Each Class\")\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T22:07:05.054690Z","iopub.execute_input":"2024-12-06T22:07:05.055106Z","iopub.status.idle":"2024-12-06T22:07:05.464658Z","shell.execute_reply.started":"2024-12-06T22:07:05.055072Z","shell.execute_reply":"2024-12-06T22:07:05.463792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\nprint(f\"Overall Accuracy: {accuracy:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T22:07:42.138897Z","iopub.execute_input":"2024-12-06T22:07:42.139775Z","iopub.status.idle":"2024-12-06T22:07:42.144961Z","shell.execute_reply.started":"2024-12-06T22:07:42.139716Z","shell.execute_reply":"2024-12-06T22:07:42.144097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"LOADING THE MODEL TO FURTHER TRAIN IT AND WORK IT TILL MAKING IT A GUI BASED APP TO NAVIGATE EASILY","metadata":{}},{"cell_type":"code","source":"print(f\"Total samples in full_dataset: {len(full_dataset)}\")\nprint(f\"Training samples: {len(train_subset)}\")\nprint(f\"Validation samples: {len(val_subset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T09:36:19.314183Z","iopub.execute_input":"2024-12-07T09:36:19.314732Z","iopub.status.idle":"2024-12-07T09:36:19.320865Z","shell.execute_reply.started":"2024-12-07T09:36:19.314678Z","shell.execute_reply":"2024-12-07T09:36:19.319946Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **STEP 8: FineTuning the Model**","metadata":{}},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Subset\n\n# Path to your organized dataset\norganized_dataset_path = '/kaggle/working/organized_dataset'\n\n# Load the full dataset\nfull_dataset = ImageFolder(root=organized_dataset_path)\n\n# Stratified split of the dataset to maintain class distribution\ntrain_indices, val_indices = train_test_split(\n    list(range(len(full_dataset))),\n    stratify=[sample[1] for sample in full_dataset.samples],\n    test_size=0.2,\n    random_state=42,\n)\n\n# Create the train and validation subsets\ntrain_dataset = Subset(full_dataset, train_indices)\nval_dataset = Subset(full_dataset, val_indices)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:20:47.668758Z","iopub.execute_input":"2024-12-07T10:20:47.669121Z","iopub.status.idle":"2024-12-07T10:20:47.708100Z","shell.execute_reply.started":"2024-12-07T10:20:47.669090Z","shell.execute_reply":"2024-12-07T10:20:47.707449Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms\n\n# Training transformations with augmentation\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(30),\n    transforms.RandomResizedCrop((224, 224)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Validation transformations (no augmentation)\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Apply transformations to datasets\ntrain_dataset = ImageFolder(root=organized_dataset_path, transform=train_transform)\nval_dataset = ImageFolder(root=organized_dataset_path, transform=val_transform)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:20:59.067069Z","iopub.execute_input":"2024-12-07T10:20:59.067722Z","iopub.status.idle":"2024-12-07T10:20:59.124382Z","shell.execute_reply.started":"2024-12-07T10:20:59.067691Z","shell.execute_reply":"2024-12-07T10:20:59.123749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import WeightedRandomSampler, DataLoader\nimport torch\n\n# Actual class counts from your dataset\nclass_counts = [327, 514, 1099, 115, 1113, 6705, 142]\nclass_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)  # Inverse of class counts\n\n# Assign a weight to each sample in the dataset based on its class\nweights = [class_weights[train_dataset.samples[i][1]] for i in range(len(train_dataset))]\n\n# Create a WeightedRandomSampler using these weights\nsampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n\n# DataLoader with the sampler for training and without for validation\ntrain_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:21:10.602629Z","iopub.execute_input":"2024-12-07T10:21:10.603347Z","iopub.status.idle":"2024-12-07T10:21:10.636657Z","shell.execute_reply.started":"2024-12-07T10:21:10.603311Z","shell.execute_reply":"2024-12-07T10:21:10.635758Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"    FROM HERE\n    ","metadata":{}},{"cell_type":"code","source":"import torch\nimport timm\nfrom torch import nn\n\n# Path to the trained model\nmodel_path = '/kaggle/input/effnet-for-sc/pytorch/default/1/efficientnet_best.pth'\n\n# Load pre-trained EfficientNet model\nmodel = timm.create_model('efficientnet_b0', pretrained=False)\n\n# Modify the classification head to match 7 classes\nmodel.classifier = nn.Linear(model.classifier.in_features, 7)\n\n# Load the saved weights\nmodel.load_state_dict(torch.load(model_path))\n\n# Move the model to the appropriate device (GPU or CPU)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = model.to(device)\n\n# Set the model to evaluation mode\nmodel.eval()\n\nprint(\"Model loaded successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:23:50.543746Z","iopub.execute_input":"2024-12-07T10:23:50.544561Z","iopub.status.idle":"2024-12-07T10:23:50.765794Z","shell.execute_reply.started":"2024-12-07T10:23:50.544528Z","shell.execute_reply":"2024-12-07T10:23:50.764860Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1.0, gamma=2.0):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n        pt = torch.exp(-ce_loss)\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n        return focal_loss.mean()\n\n# Define optimizer and learning rate scheduler\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:23:59.135660Z","iopub.execute_input":"2024-12-07T10:23:59.136133Z","iopub.status.idle":"2024-12-07T10:23:59.146818Z","shell.execute_reply.started":"2024-12-07T10:23:59.136089Z","shell.execute_reply":"2024-12-07T10:23:59.145953Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Freeze all layers initially except the classifier\nfor param in model.parameters():\n    param.requires_grad = False\nfor param in model.classifier.parameters():\n    param.requires_grad = True\n\n# Define class counts and class weights for imbalanced data\nclass_counts = [327, 514, 1099, 115, 1113, 6705, 142]  # As per the dataset\nclass_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)  # Inverse of class counts\nclass_weights = class_weights / class_weights.sum()  # Normalize\nclass_weights = class_weights.to(device)\n\n# Apply class weights in the loss function\ncriterion = FocalLoss(alpha=1.0, gamma=2.0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:24:12.411818Z","iopub.execute_input":"2024-12-07T10:24:12.412189Z","iopub.status.idle":"2024-12-07T10:24:12.421334Z","shell.execute_reply.started":"2024-12-07T10:24:12.412157Z","shell.execute_reply":"2024-12-07T10:24:12.420606Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import WeightedRandomSampler, DataLoader\n\n# Assign weights to the dataset based on class counts\nweights = [class_weights[train_dataset.samples[i][1]] for i in range(len(train_dataset))]\nsampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n\n# DataLoader with the sampler for training\ntrain_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:24:22.686616Z","iopub.execute_input":"2024-12-07T10:24:22.687305Z","iopub.status.idle":"2024-12-07T10:24:22.822645Z","shell.execute_reply.started":"2024-12-07T10:24:22.687270Z","shell.execute_reply":"2024-12-07T10:24:22.821984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef fine_tune_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=15, patience=3, device='cuda'):\n    best_val_loss = float('inf')\n    early_stop_counter = 0\n\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n        \n        # Training phase\n        model.train()\n        running_loss, correct_preds, total_samples = 0.0, 0, 0\n        \n        for images, labels in tqdm(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            # Backward pass and optimization\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            correct_preds += (preds == labels).sum().item()\n            total_samples += labels.size(0)\n\n        train_loss = running_loss / len(train_loader)\n        train_accuracy = correct_preds / total_samples\n        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n\n        # Validation phase\n        model.eval()\n        val_loss, correct_preds, total_samples = 0.0, 0, 0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n                val_loss += loss.item()\n                _, preds = torch.max(outputs, 1)\n                correct_preds += (preds == labels).sum().item()\n                total_samples += labels.size(0)\n\n        val_loss = val_loss / len(val_loader)\n        val_accuracy = correct_preds / total_samples\n        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n\n        # Early stopping\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            early_stop_counter = 0\n            torch.save(model.state_dict(), '/kaggle/working/fine_tuned_model.pth')\n            print(\"Saved best model.\")\n        else:\n            early_stop_counter += 1\n            if early_stop_counter >= patience:\n                print(\"Early stopping triggered.\")\n                break\n\n        scheduler.step()\n\n# Fine-tune the model\nfine_tune_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=15)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T11:11:37.120412Z","iopub.execute_input":"2024-12-07T11:11:37.120771Z","iopub.status.idle":"2024-12-07T11:31:05.847568Z","shell.execute_reply.started":"2024-12-07T11:11:37.120740Z","shell.execute_reply":"2024-12-07T11:31:05.846613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, roc_auc_score\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize lists to store the predictions and true labels\nall_preds = []\nall_labels = []\n\n# Evaluate on the validation data\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n        \n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Convert to numpy arrays for evaluation\nall_preds = np.array(all_preds)\nall_labels = np.array(all_labels)\n\n# Generate the classification report\nclass_names = val_dataset.classes  # Getting class names from the validation dataset\nprint(\"Classification Report:\")\nprint(classification_report(all_labels, all_preds, target_names=class_names))\n\n# Generate the confusion matrix\nprint(\"Confusion Matrix:\")\ncm = confusion_matrix(all_labels, all_preds)\nprint(cm)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:04:24.747969Z","iopub.execute_input":"2024-12-07T12:04:24.748342Z","iopub.status.idle":"2024-12-07T12:05:52.339355Z","shell.execute_reply.started":"2024-12-07T12:04:24.748309Z","shell.execute_reply":"2024-12-07T12:05:52.338409Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Binarize the labels and predictions for multi-class ROC/AUC\nnum_classes = len(class_names)\nall_labels_bin = label_binarize(all_labels, classes=range(num_classes))\nall_preds_bin = label_binarize(all_preds, classes=range(num_classes))\n\n# Compute the ROC curve and AUC for each class\nfpr, tpr, roc_auc = {}, {}, {}\n\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(all_labels_bin[:, i], all_preds_bin[:, i])\n    roc_auc[i] = roc_auc_score(all_labels_bin[:, i], all_preds_bin[:, i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(10, 8))\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot the diagonal line (random classifier line)\nplt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve for Each Class')\nplt.legend(loc='lower right')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:05:52.341270Z","iopub.execute_input":"2024-12-07T12:05:52.341675Z","iopub.status.idle":"2024-12-07T12:05:52.706751Z","shell.execute_reply.started":"2024-12-07T12:05:52.341635Z","shell.execute_reply":"2024-12-07T12:05:52.705822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy = np.sum(all_preds == all_labels) / len(all_labels)\nprint(f\"Accuracy: {accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:05:52.707905Z","iopub.execute_input":"2024-12-07T12:05:52.708197Z","iopub.status.idle":"2024-12-07T12:05:52.713264Z","shell.execute_reply.started":"2024-12-07T12:05:52.708170Z","shell.execute_reply":"2024-12-07T12:05:52.712288Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\n# Precision, Recall, and F1-Score for each class\nprecision = precision_score(all_labels, all_preds, average=None)\nrecall = recall_score(all_labels, all_preds, average=None)\nf1 = f1_score(all_labels, all_preds, average=None)\n\n# Print metrics for each class\nfor i, class_name in enumerate(class_names):\n    print(f\"Class: {class_name}\")\n    print(f\"  Precision: {precision[i]:.4f}\")\n    print(f\"  Recall: {recall[i]:.4f}\")\n    print(f\"  F1-Score: {f1[i]:.4f}\")\n    print(\"-\" * 30)\n\n# Also calculate macro and weighted averages\nmacro_precision = precision_score(all_labels, all_preds, average='macro')\nmacro_recall = recall_score(all_labels, all_preds, average='macro')\nmacro_f1 = f1_score(all_labels, all_preds, average='macro')\n\nweighted_precision = precision_score(all_labels, all_preds, average='weighted')\nweighted_recall = recall_score(all_labels, all_preds, average='weighted')\nweighted_f1 = f1_score(all_labels, all_preds, average='weighted')\n\nprint(f\"Macro Average Precision: {macro_precision:.4f}\")\nprint(f\"Macro Average Recall: {macro_recall:.4f}\")\nprint(f\"Macro Average F1-Score: {macro_f1:.4f}\")\n\nprint(f\"Weighted Average Precision: {weighted_precision:.4f}\")\nprint(f\"Weighted Average Recall: {weighted_recall:.4f}\")\nprint(f\"Weighted Average F1-Score: {weighted_f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:05:52.715076Z","iopub.execute_input":"2024-12-07T12:05:52.715850Z","iopub.status.idle":"2024-12-07T12:05:52.759399Z","shell.execute_reply.started":"2024-12-07T12:05:52.715821Z","shell.execute_reply":"2024-12-07T12:05:52.758518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_image(image_path, model, transform, device='cuda'):\n    # Load and preprocess the image\n    image = Image.open(image_path).convert('RGB')  # Ensure RGB format\n    input_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n\n    # Make prediction\n    with torch.no_grad():\n        outputs = model(input_tensor)\n        _, predicted_class = torch.max(outputs, 1)\n\n    # Map the predicted class index to the class label\n    class_idx = predicted_class.item()\n    class_label = full_dataset.classes[class_idx]  # `full_dataset` from earlier code\n\n    return class_label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:07:59.482092Z","iopub.execute_input":"2024-12-07T12:07:59.482423Z","iopub.status.idle":"2024-12-07T12:07:59.488009Z","shell.execute_reply.started":"2024-12-07T12:07:59.482397Z","shell.execute_reply":"2024-12-07T12:07:59.487099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Path to the test image\ntest_image_path = '/kaggle/input/skin-disease-test-data/test data/7.jpg'\n\n# Predict the class\npredicted_class = predict_image(test_image_path, model, test_transform, device='cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"The predicted class for the test image is: {predicted_class}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:09:09.164615Z","iopub.execute_input":"2024-12-07T12:09:09.165287Z","iopub.status.idle":"2024-12-07T12:09:09.190402Z","shell.execute_reply.started":"2024-12-07T12:09:09.165251Z","shell.execute_reply":"2024-12-07T12:09:09.189513Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"APP","metadata":{}}]}